## 设计

spray的设计不需要像gogo那样需要考虑非常多的取舍问题. spray的目标只有一个, 解决在目录fuzz领域的一切问题. 

以chainreactors一贯的风格, spray的参数设计一样的会非常复杂, 但实际上很多参数并非为人类准备, 而是为了成为更大框架的一部分. 大多数人使用spray只需要关注一些最基本的操作即可. 

**目录爆破并非只是批量发包判断状态码, 这个领域还包括了对隐藏目录的发现, 字典的自动化构造, 智能判断有效目录, 爬虫与指纹识别, 与WAF的对抗等等**

## 开源世界

spray的出发点想要自动化的分辨有效目录与无效目录, 减少对数据进行手动二次分析处理.

市面上有很多目录爆破工具或者类似的httpfuzz工具. 

* [dirsearch](https://github.com/maurosoria/dirsearch) python开发的有性能瓶颈, 有一定的智能判断逻辑, 但还不够智能
* [ffuf](https://github.com/ffuf/ffuf)  目前http fuzz领域的佼佼者, 但缺少对目录爆破的优化, 数据绝大部分情况需要二次处理才可以使用. 与spray定位有区别. 
* [feroxbuster](https://github.com/epi052/feroxbuster) 目录爆破领域的佼佼者, 与spray有着类似的定位. 无法批量爆破, 同样不够智能, 在字典处理上不够自由. 
* [gobuster](https://github.com/OJ/gobuster) 更接近go版本的dirsearch. 性能上比dirsearch更好, 能做的事情与dirsearch差不多
* [kiterunner](https://github.com/assetnote/kiterunner) 原本我很看好的项目, 一个结合了目录爆破与apifuzz的工具, 但后续没更新, 有不少bug. 
* [httpx](https://github.com/projectdiscovery/httpx) 它的设计上是为了从http协议中提取信息, 也有人用它来进行目录爆破, 效果上来说并不好, 但它对数据的一些处理方式值得学习

spray有从上面的这几个工具中学到一些东西, 也深入的分析了这些工具的优缺点, 并进行重新设计. 但请注意spray并非是对上面这些工具的重新造轮子, spray解决了不少这些工具没有考虑过的问题. 会在后续一一介绍. 

还有一些更古早, 已经停止维护的项目不再介绍.  也有一些在某个细微领域有突破的工具, 将会在后续介绍.

## 智能化

这里指的智能化, 实际上是添加复杂的规则,  代替人类进行绝大多数重复无效的劳动. 主要是将我们对目录爆破这个领域的经验转为代码. 

spray的智能判断是我们认为的最佳解决方案, 但不一定是实际上的最佳解决方案. 有可能因为智能判断反而导致了一些漏判误判. 也为此提供了多种补救与缓解方案.  我们也在不断改进我们的逻辑并不断将新的经验沉淀到spray的代码中. 

在feroxbuster与dirsearch中, 对有效目录的判断主要通过状态码与body length, 并通过这两个基础值进行一定程度的智能判断. 并通过各种手动配置的`filter`进行人工介入的二次判断. 这样的解决方案在单个目标上能通过与人类的几次交互找到一个对单个目标的最佳配置.

但如果我们想一次性对多个目标进行扫描, dirsearch与feroxbuster的手动filter逻辑直接失效, 不同网站之间完全不能使用同一个filter策略. 并且feroxbuster采用多进程的方式进行多目标并发,  几乎破坏了它原本非常优雅直观的输出界面. 

而ffuf与httpx更是几乎只用来获取原始数据, 几乎100%的需要人工介入的方式进行二次数据处理. 它们虽然也提供了各种的filter之类的功能, 但在实际使用场景上的定位更接近发包器. 

而spray采用获取两个baseline(index页面与随机页面)的方式, 动态的根据每个网站自身建立基准值的模型. 然后在后续处理中, 都会根据这两个基准值进行判断. 基本上解决了90%的场景. 

当然现实世界中不会如此简单, 只需要两个baseline不可能解决所有的问题, 为了解决后面的10%的问题以及为了性能上的优化, spray并设计了一个三段式的过滤逻辑, 每个阶段中都有大量的判断逻辑进行尽可能的智能判断. 具体的逻辑可以[文档中的细节](/wiki/spray/detail/#_1)看到. 

当然三个三段式的逻辑加上baseline解决了99%的问题, 但为了最后的1%, 设计的spray真正最复杂功能. 

这些功能包括

1. 通过模糊hash, 对网页相似度进行对比
2. 通过模糊状态码进行更进一步的动态baseline. 即模糊状态码列表中的结果会与相同状态的baseline进行对比
3. 手动维护的智能过滤状态码列表, 一定程度调整三段式逻辑
4. `--match`与`--filter`的表达式语言进行手动的规则配置

通过这几个对三段式智能过滤的补充,  我们才确定spray有了应对100%场景的能力.

当使用到3和4这两个高级功能时, 实际上spray就遇到了和feroxbuster与dirsearch类似的困境, 需要一定程度的人工手动配置了.  当然也不是没有解决办法,  只不过解决方案在spray之外, 需要引入更加庞大的分析引擎去实现. 这也是spray作为工件的意义所在. 

而通过baseline, 三段式过滤, 以及补充功能的1与2. 在非人工干预的情况下, spray能覆盖到99.9%的场景. spray已经做到了对同类工具的跨越式突破. 

## 性能

*todo*

### client

### http

## 字典构造

spray与其他目录爆破最大的不同还在于spray将字典构造引入到了目录爆破的过程中. 

在传统的解决方案之下, 工具和字典是分离的(或许有些工具提供了一些简单的替换, 例如替换host, 替换ext之类的功能, 但在实际流程上还是脱节的), 需要提前准备一个覆盖足够广的字典, 然后读取字典进行高并发的扫描. 

### 字典生成器

但在spray中, 提供了类似hashcat中的[基于掩码生成器](/wiki/spray/start/#_2)和[基于规则生成器](/wiki/spray/start/#_3), 以及一些[函数装饰器](/wiki/spray/start/#_4)对字典进行修饰, 可以在没准备字典的情况下, 对某些场景进行爆破. 

举个例子, 不少大型机构, 会使用一台nginx对内网的多个服务进行反代, 而这样的反代绝大多数情况都是通过一个较短的path. 例如`plms`这样的缩写.  使用spray的掩码生成器, 生成一个四位的随机目录字典, 或者可以带上目标的一些关键字进行更复杂的掩码字典生成结合规则字典生成. 

### 递归

在现代化的网站中, 递归实际上效果并不好, spray并不鼓励使用递归. 

在传统的目录爆破工具中, 通常包含一个递归配置, 将爆破到的所有目录都在进行一次全量的字典爆破. 

但spray中提供了另一种选择,  可以通过类似`--recu current.IsDir() && current.Status == 200`配置自定义的递归规则, 进行相对高效的递归. 

虽然spray提供了相对高效的递归方式, 但还是不建议使用递归. 

### 轻量级的递归

在spray中, 更优雅的解决方案是基于规则的进一步字典生成.  

提供了`--append-rule`, 可以根据有效目录进行额外的字典生成. 这个是在爆破到某些目录之后, 进行进一步的字典组合.

例如, 想要扫描有效文件的备份, 当扫到了`index.php`的时候, 自动根据指定的字典, 生成如`index.php~`这样的字典, 进行爆破. 

## 信息收集

spray的输出结果更像是httpx与ffuf那样, 不仅仅只有目录. 有不少目录爆破工具在输出结果时, 抛弃了所有中间输出, 导致对其二次处理还需要httpx这样的工具配合,再次获取信息. 会额外发送不少请求包. 

spray的[文件输出结果](/wiki/spray/start/#_7)中, 包含了完整的请求摘要信息. 

在目录爆破时, spray还将对title, 指纹进行识别, 并提供了`--extract`自定义正则从网页中提取数据. 也包含了一个简易的爬虫. 

### 指纹

目前, 除了httpx提供了wappalyzer的规则库, 其他工具都没有实现类似的功能. 

而wappalyzer关注的主要是网站的组件, 例如使用了什么语言, 引入了什么组件. 它的关注点与渗透测试场景实际上并不一致. 在红队/渗透测试场景中, 更需要的是类似whatweb那样的指纹识别, 供应商识别.

而spray与gogo共享了指纹库, 实现了对数千条红队可能会关注的指纹的识别.  

并且同样引入了主动指纹识别, 根据配置生成可能存在关键信息的目录进行爆破. 这里的逻辑与gogo中的主动指纹识别有细微的不同. spray会将需要主动探测的目录生成一个字典, 并进行全量的规则匹配. 而非gogo那样的精准匹配.  因此实际上spray在配置了相同的指纹的情况下, 会比gogo有些许提升(可能只能提升1%不到, 某些情况下能带来惊喜)

spray没有gogo那么多顾虑, 后续也可能会考虑将wappalyzer接入, 提供更丰富的信息.

### 爬虫

爬虫的逻辑类似[jsfinder](https://github.com/Threezh1/JSFinder), 从网页中提取可能的url, 并进行递归的爬虫处理. 

这个爬虫的表现远低于headless爬虫, 如果有更高级的需要, 还是简易使用[katana](https://github.com/projectdiscovery/katana) , [rad,](https://github.com/chaitin/rad) 或[crawlgo](https://github.com/Qianlitp/crawlergo) 这样的headless爬虫工具.

当这个爬虫与智能过滤结合到一起, 就自然而然的实现了对这些有效目录的验证. 

### 其他方式

除了爬虫和主动指纹识别之外, spray目前还提供了扫描备份文件, 通用文件的选项. 当然手法不止这些, 如果有spray还不支持的类似的功能, 欢迎提供issue.

### 数据二次处理

因为spray的输出格式接近httpx与ffuf, 同样支持对他的数据的进行二次处理, 可以像httpx与ffuf一样使用spray.

后续还会提供完整的响应包的原始数据. 用作进一步的的数据分析. 甚至实现类似nuclei中offline scan一样的功能. 

## 批量与分布式

 *todo*